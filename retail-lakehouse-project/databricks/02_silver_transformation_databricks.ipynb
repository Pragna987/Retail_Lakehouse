{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f1d582",
   "metadata": {},
   "source": [
    "# Silver Layer Transformation - Databricks\n",
    "\n",
    "This notebook creates cleaned, enriched Silver tables from Bronze Delta tables.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Bronze layer ingestion completed\n",
    "- Tables exist in `/FileStore/instacart/bronze/`\n",
    "\n",
    "**Output:**\n",
    "- Enriched tables in `/FileStore/instacart/silver/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BRONZE_PATH = \"/FileStore/instacart/bronze\"\n",
    "SILVER_PATH = \"/FileStore/instacart/silver\"\n",
    "\n",
    "print(f\"Bronze input path: {BRONZE_PATH}\")\n",
    "print(f\"Silver output path: {SILVER_PATH}\")\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8158a02",
   "metadata": {},
   "source": [
    "## Step 1: Create Product Master Table\n",
    "\n",
    "Join products with aisles and departments to create complete product catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "# Read Bronze tables\n",
    "products_df = spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/products\")\n",
    "aisles_df = spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/aisles\")\n",
    "departments_df = spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/departments\")\n",
    "\n",
    "# Join to create product master\n",
    "product_master = products_df \\\n",
    "    .join(aisles_df, \"aisle_id\", \"left\") \\\n",
    "    .join(departments_df, \"department_id\", \"left\") \\\n",
    "    .select(\n",
    "        col(\"product_id\"),\n",
    "        col(\"product_name\"),\n",
    "        col(\"aisle_id\"),\n",
    "        col(\"aisle\"),\n",
    "        col(\"department_id\"),\n",
    "        col(\"department\")\n",
    "    ) \\\n",
    "    .withColumn(\"processing_timestamp\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "product_master.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(f\"{SILVER_PATH}/product_master\")\n",
    "\n",
    "count = product_master.count()\n",
    "print(f\"✓ Created product_master with {count:,} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a431cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview product master\n",
    "print(\"Product Master - Sample Data:\")\n",
    "display(product_master.limit(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5e5ea",
   "metadata": {},
   "source": [
    "## Step 2: Create Enriched Order Products (Prior)\n",
    "\n",
    "Join order_products_prior with orders and product information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f438ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Bronze tables\n",
    "order_products_prior_df = spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/order_products_prior\")\n",
    "orders_df = spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/orders\")\n",
    "product_master_df = spark.read.format(\"delta\").load(f\"{SILVER_PATH}/product_master\")\n",
    "\n",
    "# Join to create enriched table\n",
    "order_products_prior_enriched = order_products_prior_df \\\n",
    "    .join(orders_df, \"order_id\", \"inner\") \\\n",
    "    .join(product_master_df, \"product_id\", \"inner\") \\\n",
    "    .select(\n",
    "        col(\"order_id\"),\n",
    "        col(\"user_id\"),\n",
    "        col(\"order_number\"),\n",
    "        col(\"order_dow\"),\n",
    "        col(\"order_hour_of_day\"),\n",
    "        col(\"days_since_prior_order\"),\n",
    "        col(\"product_id\"),\n",
    "        col(\"product_name\"),\n",
    "        col(\"aisle_id\"),\n",
    "        col(\"aisle\"),\n",
    "        col(\"department_id\"),\n",
    "        col(\"department\"),\n",
    "        col(\"add_to_cart_order\"),\n",
    "        col(\"reordered\")\n",
    "    ) \\\n",
    "    .withColumn(\"processing_timestamp\", current_timestamp())\n",
    "\n",
    "# Write to Silver with partitioning\n",
    "order_products_prior_enriched.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"department_id\") \\\n",
    "    .save(f\"{SILVER_PATH}/order_products_prior_enriched\")\n",
    "\n",
    "count = order_products_prior_enriched.count()\n",
    "print(f\"✓ Created order_products_prior_enriched with {count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be970ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview enriched prior orders\n",
    "print(\"Order Products Prior (Enriched) - Sample Data:\")\n",
    "display(order_products_prior_enriched.limit(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f023e",
   "metadata": {},
   "source": [
    "## Step 3: Create Enriched Order Products (Train)\n",
    "\n",
    "Same enrichment for training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Bronze table\n",
    "order_products_train_df = spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/order_products_train\")\n",
    "\n",
    "# Join to create enriched table\n",
    "order_products_train_enriched = order_products_train_df \\\n",
    "    .join(orders_df, \"order_id\", \"inner\") \\\n",
    "    .join(product_master_df, \"product_id\", \"inner\") \\\n",
    "    .select(\n",
    "        col(\"order_id\"),\n",
    "        col(\"user_id\"),\n",
    "        col(\"order_number\"),\n",
    "        col(\"order_dow\"),\n",
    "        col(\"order_hour_of_day\"),\n",
    "        col(\"days_since_prior_order\"),\n",
    "        col(\"product_id\"),\n",
    "        col(\"product_name\"),\n",
    "        col(\"aisle_id\"),\n",
    "        col(\"aisle\"),\n",
    "        col(\"department_id\"),\n",
    "        col(\"department\"),\n",
    "        col(\"add_to_cart_order\"),\n",
    "        col(\"reordered\")\n",
    "    ) \\\n",
    "    .withColumn(\"processing_timestamp\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "order_products_train_enriched.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"department_id\") \\\n",
    "    .save(f\"{SILVER_PATH}/order_products_train_enriched\")\n",
    "\n",
    "count = order_products_train_enriched.count()\n",
    "print(f\"✓ Created order_products_train_enriched with {count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dba041",
   "metadata": {},
   "source": [
    "## Step 4: Create User Order Summary\n",
    "\n",
    "Aggregate user-level statistics from orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9978e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, avg, max as spark_max\n",
    "\n",
    "# Aggregate user statistics\n",
    "user_order_summary = orders_df \\\n",
    "    .groupBy(\"user_id\") \\\n",
    "    .agg(\n",
    "        count(\"order_id\").alias(\"total_orders\"),\n",
    "        spark_max(\"order_number\").alias(\"max_order_number\"),\n",
    "        avg(\"order_dow\").alias(\"avg_order_dow\"),\n",
    "        avg(\"order_hour_of_day\").alias(\"avg_order_hour\"),\n",
    "        avg(\"days_since_prior_order\").alias(\"avg_days_between_orders\")\n",
    "    ) \\\n",
    "    .withColumn(\"processing_timestamp\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "user_order_summary.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(f\"{SILVER_PATH}/user_order_summary\")\n",
    "\n",
    "count = user_order_summary.count()\n",
    "print(f\"✓ Created user_order_summary with {count:,} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e54af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview user summary\n",
    "print(\"User Order Summary - Sample Data:\")\n",
    "display(user_order_summary.limit(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873fc13",
   "metadata": {},
   "source": [
    "## Verify Silver Tables\n",
    "\n",
    "List all created Silver tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Silver tables\n",
    "silver_tables = dbutils.fs.ls(SILVER_PATH)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SILVER LAYER TRANSFORMATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nSilver tables created:\")\n",
    "for table in silver_tables:\n",
    "    print(f\"  ✓ {table.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5525fc",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **Silver layer transformation complete!**\n",
    "\n",
    "**Tables created:**\n",
    "- `product_master` - Complete product catalog with hierarchy\n",
    "- `order_products_prior_enriched` - Historical purchases with full product info\n",
    "- `order_products_train_enriched` - Training data enriched\n",
    "- `user_order_summary` - User-level aggregates\n",
    "\n",
    "**Next steps:**\n",
    "1. Run `03_gold_aggregation_databricks` to create business metrics\n",
    "2. Explore Silver tables in Data Explorer"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
